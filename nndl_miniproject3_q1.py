# -*- coding: utf-8 -*-
"""NNDL Miniproject3 Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15tMBdsPRhxsi-YhxAZR94_AYbXhsu28L

## Imports
"""

import numpy as np
import pandas as pd
import torch
from torch import nn, optim
import torch.nn.functional as F
from torchvision import datasets, transforms
from tqdm import tqdm
import matplotlib.pyplot as plt

"""# **Variational Autoencoder**

## **VAE Implementation**
In this class, we implement Variational Autoencoder.
This network has three layers for encoding and 3 layers for decoding that they are counter part of each other.

Encode part implemented as `encode` function. Output of this layer is two dimension for each of $\mu$ and logvar.

Decode part implemented as `encode` function.

Forward function gathered them. At first, run encode part. After that it reparametrized it to make it possible to back propagate. It's implemented in `reparameterize` funciton. At the end, run decode part and output it with $\mu$ and logvar.
"""

class VAE(nn.Module):
  def __init__(self, image_channels=784, latent_dim=2):
    super(VAE, self).__init__()
    
    self.enc_fc_1 = nn.Linear(image_channels, 400)
    self.enc_fc_2 = nn.Linear(400, 200)
    self.enc_fc_3_mu = nn.Linear(200, latent_dim)
    self.enc_fc_3_logvar = nn.Linear(200, latent_dim)

    self.dec_fc_1 = nn.Linear(latent_dim, 200)
    self.dec_fc_2 = nn.Linear(200, 400)
    self.dec_fc_3 = nn.Linear(400, image_channels)

    self.activation_func = F.relu

  def encode(self, input):
    out = self.enc_fc_1(input)
    out = self.activation_func(out)
    out = self.enc_fc_2(out)
    out = self.activation_func(out)
    out_mu = self.enc_fc_3_mu(out)
    out_logvar = self.enc_fc_3_logvar(out)
    return out_mu, out_logvar

  def reparameterize(self, mu, logvar):
    std = torch.exp(0.5*logvar)
    eps = torch.randn_like(std)
    return mu + eps*std

  def decode(self, input):
    out = self.dec_fc_1(input)
    out = self.activation_func(out)
    out = self.dec_fc_2(out)
    out = self.activation_func(out)
    out = self.dec_fc_3(out)
    out = torch.sigmoid(out)
    return out

  def forward(self, input):
    mu, logvar = self.encode(input)
    z = self.reparameterize(mu, logvar)
    return self.decode(z), mu, logvar

"""## Loss funciton
It's combination of Binary class entropy with KL Divergence. Full explanation of this functions come in report.
"""

def loss_function(reconstruction_x, x, mu, logvar):
    BCE = F.binary_cross_entropy(reconstruction_x, x, reduction='sum')
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + KLD

"""## Train
For training, We input features to model and get output. Then calculate loss function and back propagate it. We append losses to an array. 

We do it for some of outputs to generate some middle results to see model progress.

`evaluate_VAE` run model on some data and plot it's output.
"""

def train_VAE(model, train_loader, epochs_num, optimizer):
  epochs_train_loss = []
  train_size = 0
  test_inputs, _ = next(iter(train_loader))  
  test_inputs = test_inputs.cuda().view(-1, 784)
  test_outputs = []

  for i, epoch in tqdm(enumerate(range(1, epochs_num+1))):
    batches_train_loss = []

    for index, data in enumerate(train_loader):
      features, targets = data
      train_size += len(features)
      features = features.float() 
      targets = targets.float()
      features, targets = features.cuda(), targets.cuda()
      optimizer.zero_grad()
      features = features.view(-1, 784)
      reconstruction_batch, mu, logvar = model(features)
      loss = loss_function(reconstruction_batch, features, mu, logvar)
      loss.backward()
      optimizer.step()
      batches_train_loss.append(loss.item())
    
    with torch.no_grad():
      test_output, _, _ = model(test_inputs)
      test_outputs.append(test_output)

    epochs_train_loss.append(np.sum(batches_train_loss)/train_size)
    print('Epoch {} is finished!'.format(epoch))
  return epochs_train_loss, test_outputs

def evaluate_VAE(loader, model):
  all_targets = []
  latent_space = []
  all_outputs = []
  all_inputs = []
  with torch.no_grad():
    for features, target in loader:
      all_targets.append(np.array(target))
      features, target = features.cuda(), target.cuda()
      features = features.float() 
      target = target.float()
      features = features.view(-1, 784)
      out_mu,out_logvar = model.encode(features)
      out = model.reparameterize(out_mu, out_logvar)
      latent_space.append(out)
      out = model.decode(out)
      all_outputs.append(out)
      all_inputs.append(features)
  return all_targets, latent_space, all_outputs, all_inputs

"""## Plot Result
This funciton is for plotting losses against epoch number.
"""

def plot_result(epochs_train, epochs_num, title):
  x_axis = range(1, epochs_num+1)
  legends = ['train']
  x_label = 'Epoch'
  plt.plot(x_axis, epochs_train)
  plt.title(title)
  plt.xlabel(x_label)
  plt.legend(legends)
  plt.show()

"""This function is for plotting different classes distribution in latent space."""

def plot_latent_space(scatter_x, scatter_y, group):
  cdict = ['blue', 'red', 'green', 'yellow', 'pink', 'gray', 'black', 'orange', 'olive', 'purple']

  fig, ax = plt.subplots(figsize=(10,10))
  for g in np.unique(group):
      ix = np.where(group == g)
      ax.scatter(scatter_x[ix], scatter_y[ix], c = cdict[g], label = g, s = 100)
  ax.legend()
  plt.show()

"""This funciton show some numbers images.

"""

def show_numbers(numbers):
  columns = 10
  rows = 10
  fig = plt.figure(figsize=(columns, rows))
  for i,number in enumerate(numbers):
    fig.add_subplot(rows, columns, i+1)
    number = number.reshape(28,28)
    plt.imshow(number, cmap="gray")
    plt.axis('off')

"""## Prepare Data
We get MNIST train set from torch datasets.
"""

train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.ToTensor()),
    batch_size=64, shuffle=True)

"""## Run VAE
We run our model with `Adam` optimizer and small learning rate for 50 epochs.
"""

model_VAE = VAE()
model_VAE.cuda()
optimizer_VAE = optim.Adam(model_VAE.parameters(), lr=1e-3)

epochs_train_loss_VAE, test_results = train_VAE(model_VAE, train_loader, 50, optimizer_VAE)

"""At the end of training, We plot some of digits in different epochs to see progress of model learning."""

test_results_VAE = np.array([np.array(j.cpu()) for i in test_results for j in i])

for epoch in np.arange(50, step=5):
  epoch_res = test_results_VAE[epoch*64:epoch*64+64]
  show_numbers(epoch_res)

"""And plotting loss in different epochs and it's good progress."""

plot_result(epochs_train_loss_VAE, 50, "Loss")

"""## Analyze Latent Space
We plot data distribution of different classes to examine distribution and relation of different classes.
"""

targets_VAE, latent_space_VAE, model_outputs_VAE, model_inputs_VAE = evaluate_VAE(train_loader, model_VAE)

targets_VAE = np.array([j for i in targets_VAE for j in i])
latent_space_VAE = np.array([np.array(j.cpu()) for i in latent_space_VAE for j in i])

model_outputs_VAE = np.array([np.array(j.cpu()) for i in model_outputs_VAE for j in i])
model_inputs_VAE = np.array([np.array(j.cpu()) for i in model_inputs_VAE for j in i])

plot_latent_space(latent_space_VAE.T[0], latent_space_VAE.T[1], targets_VAE)

"""In this part, we calculate min and max of each dimension of latent space. And generate some middle points in this two dimensions of latent space.

After that, we plot this points to see this range change of digits feature in latent space.
"""

min_x = latent_space_VAE.T[0].min()
max_x = latent_space_VAE.T[0].max()

min_y = latent_space_VAE.T[1].min()
max_y = latent_space_VAE.T[1].max()

x = np.arange(min_x, max_x, (max_x-min_x)/10)

y = np.arange(min_y, max_y, (max_y-min_y)/10)[::-1]

inp = []
for j in y:
  for i in x:
    inp.append(np.array([i, j]))
inp = torch.from_numpy(np.array(inp)).float().cuda()

out = model_VAE.decode(inp)
show_numbers(out.cpu().data.numpy())

"""## Analyze VAE Output
We generate some random indices for inputing to VAE. Then input this data to model and get output of model and plot it.
"""

random_index_VAE = np.random.choice(model_inputs_VAE.shape[0], 50, replace=False)

random_targets_VAE = targets_VAE[random_index_VAE]
random_inputs_VAE = model_inputs_VAE[random_index_VAE]
random_outputs_VAE = model_outputs_VAE[random_index_VAE]

random_targets_VAE

show_numbers(random_inputs_VAE)

show_numbers(random_outputs_VAE)

"""# **Conditional Variational Autoencoder**

## CVAE Implementation
In this class, we implement Conditional Variational Autoencoder.
Architecture of this network is similiar to `VAE` network.

Only difference is getting condition in encode and decode function. This functions concat this condition to input and then enter it to the pipeline.
"""

class CVAE(nn.Module):
  def __init__(self, image_channels=784, latent_dim=2):
    super(CVAE, self).__init__()
    
    self.enc_fc_1 = nn.Linear(image_channels+10, 400)
    self.enc_fc_2 = nn.Linear(400, 200)
    self.enc_fc_3_mu = nn.Linear(200, latent_dim)
    self.enc_fc_3_logvar = nn.Linear(200, latent_dim)

    self.dec_fc_1 = nn.Linear(latent_dim+10, 200)
    self.dec_fc_2 = nn.Linear(200, 400)
    self.dec_fc_3 = nn.Linear(400, image_channels)

    self.activation_func = F.relu

  def encode(self, input, cond):
    x = torch.cat([input, cond], 1)
    out = self.enc_fc_1(x)
    out = self.activation_func(out)
    out = self.enc_fc_2(out)
    out = self.activation_func(out)
    out_mu = self.enc_fc_3_mu(out)
    out_logvar = self.enc_fc_3_logvar(out)
    return out_mu,out_logvar

  def reparameterize(self, mu, logvar):
    std = torch.exp(0.5*logvar)
    eps = torch.randn_like(std)
    return mu + eps*std

  def decode(self, input, cond):
    x = torch.cat([input, cond], 1)
    out = self.dec_fc_1(x)
    out = self.activation_func(out)
    out = self.dec_fc_2(out)
    out = self.activation_func(out)
    out = self.dec_fc_3(out)
    out = torch.sigmoid(out)
    return out

  def forward(self, input, cond):
    mu, logvar = self.encode(input, cond)
    z = self.reparameterize(mu, logvar)
    return self.decode(z, cond), mu, logvar

"""## Train and Test
This is similiar to vae training. The only difference is one hot encoding labels to enter them as condition.

After that, input them as condition to model and get desired output.
"""

def train_CVAE(model, train_loader, epochs_num, optimizer):
  epochs_train_loss = []
  train_size = 0
  test_inputs, test_targets = next(iter(train_loader))  
  test_targets = one_hot(test_targets, 10).float().cuda()
  test_inputs = test_inputs.cuda().view(-1, 784)
  test_outputs = []

  for i, epoch in tqdm(enumerate(range(1, epochs_num+1))):
    batches_train_loss = []

    for index, data in enumerate(train_loader):
      features, targets = data
      train_size += len(features)
      features = features.float() 
      # targets = targets.float()
      targets = one_hot(targets, 10).float()
      features, targets = features.cuda(), targets.cuda()
      optimizer.zero_grad()
      features = features.view(-1, 784)
      reconstruction_batch, mu, logvar = model(features, targets)
      loss = loss_function(reconstruction_batch, features, mu, logvar)
      loss.backward()
      optimizer.step()

      batches_train_loss.append(loss.item())

    with torch.no_grad():
      test_output, _, _ = model(test_inputs, test_targets)
      test_outputs.append(test_output)
    
    epochs_train_loss.append(np.sum(batches_train_loss)/train_size)
    print('Epoch {} is finished!'.format(epoch))
  return epochs_train_loss, test_outputs

"""This is the same with same difference that explained in previous parts..."""

def evaluate_CVAE(loader, model):
  all_targets = []
  latent_space = []
  all_outputs = []
  all_inputs = []
  with torch.no_grad():
    for features, target in loader:
      all_targets.append(np.array(target))
      features = features.float()
      target = one_hot(target, 10)
      features, target = features.cuda(), target.cuda() 
      # target = target.float()
      features = features.view(-1, 784)
      out_mu, out_logvar = model.encode(features, target)
      out = model.reparameterize(out_mu, out_logvar)
      latent_space.append(out)
      out = model.decode(out, target)
      all_outputs.append(out)
      all_inputs.append(features)
  return all_targets, latent_space, all_outputs, all_inputs

"""## Run CVAE

We run our model and train it for 50 epochs.
"""

model_CVAE = CVAE()
model_CVAE.cuda()
optimizer_CVAE = optim.Adam(model_CVAE.parameters(), lr=1e-3)

"""This funciton one hot encode labels with respect to class count."""

def one_hot(labels, class_size):
  targets = torch.zeros(labels.size(0), class_size)
  for i, label in enumerate(labels):
      targets[i, label] = 1
  return targets

epochs_train_loss_CVAE, test_results = train_CVAE(model_CVAE, train_loader, 50, optimizer_CVAE)

"""Plotting loss against different epochs..."""

plot_result(epochs_train_loss_CVAE, 50, "Loss")

"""Plotting results in different epochs to see progress of model learning...

"""

test_results_CVAE = np.array([np.array(j.cpu()) for i in test_results for j in i])
for epoch in np.arange(50, step=5):
  epoch_res = test_results_CVAE[epoch*64:epoch*64+64]
  show_numbers(epoch_res)

"""## Analyze Latent Space
Here, we draw data distribution of different classes in latent space.

Generating new np arrays needed to make data compatible for drawing.

Different classes points have great intersection for generating good new data points.
"""

targets_CVAE, latent_space_CVAE, model_outputs_CVAE, model_inputs_CVAE = evaluate_CVAE(train_loader, model_CVAE)

targets_CVAE = np.array([j for i in targets_CVAE for j in i])
latent_space_CVAE = np.array([np.array(j.cpu()) for i in latent_space_CVAE for j in i])

model_outputs_CVAE = np.array([np.array(j.cpu()) for i in model_outputs_CVAE for j in i])
model_inputs_CVAE = np.array([np.array(j.cpu()) for i in model_inputs_CVAE for j in i])

plot_latent_space(latent_space_CVAE.T[0], latent_space_CVAE.T[1], targets_CVAE)

"""Drawing latent space images through two dimension with label 8...

As you see, 8 entered as one hot encoded condition and result is 8 with different orientation and loop size.
"""

min_x = latent_space_VAE.T[0].min()
max_x = latent_space_VAE.T[0].max()

min_y = latent_space_VAE.T[1].min()
max_y = latent_space_VAE.T[1].max()

x = np.arange(min_x, max_x, (max_x-min_x)/10)

y = np.arange(min_y, max_y, (max_y-min_y)/10)[::-1]

inp = []
for j in y:
  for i in x:
    inp.append(np.array([i, j]))

inp = torch.from_numpy(np.array(inp)).float().cuda()
cond_label = 8
selected_label = one_hot(torch.from_numpy(np.array([cond_label for i in range(len(inp))])), 10).cuda()
out = model_CVAE.decode(inp, selected_label)
show_numbers(out.cpu().data.numpy())

"""## Analayze CVAE output

We use previous indices to be able to compare it with `VAE`.

We show output of this model for previous samples.
You can more quality in output because of setting real labels as condition.
"""

random_index_CVAE = random_index_VAE.copy()

random_inputs_CVAE = random_inputs_VAE.copy()
random_inputs_CVAE = torch.from_numpy(random_inputs_CVAE).cuda()
random_targets_CVAE = one_hot(torch.from_numpy(targets_VAE[random_index_CVAE]), 10).float()
random_targets_CVAE = random_targets_CVAE.cuda()
random_outputs_CVAE,_,_ = model_CVAE(random_inputs_CVAE, random_targets_CVAE)

targets_VAE[random_index_CVAE]

show_numbers(random_inputs_CVAE.cpu().data.numpy())

show_numbers(random_outputs_CVAE.cpu().data.numpy())